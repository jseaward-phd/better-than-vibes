{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbc4623-54e3-4ad1-bfa0-58c04b653996",
   "metadata": {},
   "source": [
    "# Better Than Vibes\n",
    "    \n",
    "While training and fine-tuning models models in a shoestring budget, the question of whether or not we had enough data was a constant problem. Is the problem with the model architecture? the implementation? or do we need more//better data? When I asked how we knew such and such data was enough the answer typically boiled down to \"vibes.\" Let us see if we can do ***better than vibes.***\n",
    "\n",
    "Marginalia provided in the code blocks.\n",
    "\n",
    "## Introduction: Information Theory\n",
    "\n",
    "Shannon information, $I$, is the measure of information a character in a message brings to a receiver. The information a character $a$ brings is written $$I(a) = -\\log(p_a),$$ where $p_a$ is the probability that the character $a$ will be received. This probability is conditioned on the previous characters in the message *and* prior knowledge about the type of message. For example, a \"u\" following a \"q\" when the message is in English carries almost no information, since \"u\" nearly always follows \"q\" (conversely, any other letter carries large amounts of information, narrowing down the rest of the possible characters to only a handful). On the other hand, if the message were encrypted in such a way that all characters were equally likely, \"u\" after \"q\" would carry just as much information as any other character, them all having equal probability.\n",
    "\n",
    "Turning back to machine learning, we can think of each sample in a test set as a message, beginning with the data and ending with the label(s). A model, then, is a machine that guesses the label(s), conditioned on the data *and* what it has seen during training. What we want a model to do is learn the patterns that allow one to infer the next part of a message, given the first part. A language model trained on English text would have learned that \"u\" nearly allows follows \"q\", for instance. We can then think of each *label* in a data set as holding a certain amount of information, depending on what the model has already learned. From here, we can start asking questions about how much data is enough and which data sets will be more useful for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7a114a-2ce7-4fc4-a88c-b6a8f24a5d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenML Dataset\n",
      "==============\n",
      "Name..........: electricity\n",
      "Version.......: 13\n",
      "Format........: arff\n",
      "Upload Date...: 2022-07-10 10:34:54\n",
      "Licence.......: Public\n",
      "Download URL..: https://api.openml.org/data/v1/download/22103281/electricity.arff\n",
      "OpenML URL....: https://www.openml.org/d/44156\n",
      "# of features.: 9\n",
      "# of instances: 38474\n"
     ]
    }
   ],
   "source": [
    "# Import the module and get a dataset\n",
    "import btv\n",
    "\n",
    "# 44156 is the id for the \"electricity\" datasset, predicting whether the price of electricty rises or falls week to week.\n",
    "# Feel free to chose another from the openML catalogue (https://www.openml.org/search?type=data&status=active)\n",
    "# Make sure to update the name of the class column argument if necessary.\n",
    "df, X, y = btv.data_tab.dataset2df(44156, class_cols=[\"class\"], verbose=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ee45c-cd31-40c3-b648-e4cd3beb9286",
   "metadata": {},
   "source": [
    "### Label information without any data\n",
    "Without looking at the data or deploying any kind of model, the labels necessarily hold a lot of information. All we have to go on to guess the label of any given data point is the frequency of the label's occurrence. The information in each label, $y_i=c_i$, is written $$I(y_i) = -\\log_2[p(y_i=c_i)]$$ where the probability of label $y_i$ being the correct class for the sample, $c_i$, can only be crudely estimated. Note that data of the sample, $x_i$, plays no role and the base of the logarithm makes the unit of information the bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3974962-2955-459d-b369-386f3893ce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information in the test set assuming p(label) == 1/# of classes:\n",
      " 7695.0\n",
      "Information in the test set assuming p(label) == 1/# of label ouccurances:\n",
      " 7694.988657169631\n"
     ]
    }
   ],
   "source": [
    "naive_test_info = btv.core.chance_info(y_test,use_freq=False)\n",
    "frequnecy_test_info = btv.core.chance_info(y_test,use_freq=True)\n",
    "print(\"Information in the test set assuming p(label) == 1/# of classes:\\n\", naive_test_info)\n",
    "print(\"Information in the test set assuming p(label) == 1/# of label ouccurances:\\n\", frequnecy_test_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb18cce-78ea-47c8-8cea-0fb50030a19a",
   "metadata": {},
   "source": [
    "The frequency-aware information should be *lower* than the one based only on the number of classes, that reflecting the actual distribution of labels better. If they are close, that means the samples are very evenly distributed between the classes.\n",
    "### Information remaining for a trained model\n",
    "After training, a model will be able to use the data to infer the label. Therefore the information in the label for a trained model will be much less than using just frequency statistics. It can be written $$I(y_i|x_i) = -\\log_2[p(y_i=c_i|x_i)],$$ where $p(y_i=c_i|x_i)$ is the probability estimation the classifier gives to the correct class. A *perfect* model would know every label with certainty from it's data, guess every label correctly with probability one, giving $I=0$ for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eb940ff-44b9-4aac-bf76-c8986d825b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information in the test set from frqunecy stats: 7694.989\n",
      "Information remaining in test set for trained classifier: 1726.200\n",
      "Score when trained on full training set: : 0.81442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier # a classic for tabulat data\n",
    "# feel free to use another classifier. The methods called will be .fit(X,y), .predict_proba(X), and .score(X,y)\n",
    "clf = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=1.0, max_depth=1, random_state=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "predicted_label_probabilities = clf.predict_proba(X_test)\n",
    "trained_test_info = btv.core.prediction_info(y_test, predicted_label_probabilities).sum() # function returns the information of each label\n",
    "full_train_score = clf.score(X_test, y_test)\n",
    "\n",
    "print(f\"Information in the test set from frqunecy stats: {frequnecy_test_info:.3f}\")\n",
    "print(f\"Information remaining in test set for trained classifier: {trained_test_info:.3f}\")\n",
    "print(f\"Score when trained on full training set: : {full_train_score:0.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08dcab-2a13-4e48-9dbf-c0ae62d30d6d",
   "metadata": {},
   "source": [
    "Since the Shannon information of message can be thought of as the amount of information needed to specify the message, a better-trained model need less information about (or \"leave less information in\" if you use the thermodynamic analogy of information being hidden in a system) a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0377d2ea-d47b-462a-a85c-4d562c98ee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information in the test set from frqunecy stats: 7694.989\n",
      "Information remaining in test set for fully-trained classifier: 1726.200\n",
      "Score when trained on full training set: : 0.81442\n",
      "Information remaining in test set for minimum-trained classifier: 2367.289\n",
      "Score when trained on minimum training set: : 0.70292\n"
     ]
    }
   ],
   "source": [
    "# Select a minimum training set, one that only includes one of every label\n",
    "min_idx, _ = btv.core.collect_min_set(y_train)\n",
    "X_min, y_min = X_train[min_idx] , y_train[min_idx]\n",
    "\n",
    "# Fitting to this minimum set will result in a functional, but poor classifier\n",
    "clf.fit(X_min, y_min)\n",
    "min_trained_predicted_test_probabilities = clf.predict_proba(X_test)\n",
    "min_trained_test_info = btv.core.prediction_info(y_test, min_trained_predicted_test_probabilities).sum()\n",
    "min_trained_score = clf.score(X_test,y_test)\n",
    "\n",
    "print(f\"Information in the test set from frqunecy stats: {frequnecy_test_info:.3f}\")\n",
    "print(f\"Information remaining in test set for fully-trained classifier: {trained_test_info:.3f}\")\n",
    "print(f\"Score when trained on full training set: : {full_train_score:0.5f}\")\n",
    "print(f\"Information remaining in test set for minimum-trained classifier: {min_trained_test_info:.3f}\")\n",
    "print(f\"Score when trained on minimum training set: : {min_trained_score:0.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ddcba-d7a0-4ff2-b59b-b6269610f7ce",
   "metadata": {},
   "source": [
    "The amount of information left in a test set is more than just anoter metric for classifier performance. The more ignorant a classifier is about a set, the more it can potentially learn from it.\n",
    "#### Looking at the information remaining in the training set after training on subsets of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389ec679-d252-4061-b6f7-398c5f1c0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information in the training set from frqunecy stats: 30778.997\n",
      "Information remaining in train set for minimum-trained classifier: 9667.596\n",
      "Information remaining in train set for tenth-trained classifier: 7132.725\n",
      "Information remaining in train set for fully-trained classifier: 6953.905\n"
     ]
    }
   ],
   "source": [
    "frequnecy_train_info = btv.core.chance_info(y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "full_trained_train_info = btv.core.prediction_info(y_train, clf.predict_proba(X_train)).sum()\n",
    "clf.fit(X_train[:len(y_train)//10], y_train[:len(y_train)//10])\n",
    "tenth_trained_train_info = btv.core.prediction_info(y_train, clf.predict_proba(X_train)).sum()\n",
    "clf.fit(X_min, y_min)\n",
    "min_trained_train_info = btv.core.prediction_info(y_train, clf.predict_proba(X_train)).sum()\n",
    "\n",
    "print(f\"Information in the training set from frqunecy stats: {frequnecy_train_info:.3f}\")\n",
    "print(f\"Information remaining in train set for minimum-trained classifier: {min_trained_train_info:.3f}\")\n",
    "print(f\"Information remaining in train set for tenth-trained classifier: {tenth_trained_train_info:.3f}\")\n",
    "print(f\"Information remaining in train set for fully-trained classifier: {full_trained_train_info:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc6438-b1e2-4cce-b5f4-901818c17baf",
   "metadata": {},
   "source": [
    "And different training sets can have different amounts of information *about* the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c6ec68a-a1fb-44d7-9916-22fffe6b2543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information in the test set from frqunecy stats: 7694.989\n",
      "Information remaining in test set for fully-trained classifier: 1726.200\n",
      "Score when trained on full training set: : 0.81442\n",
      "Information remaining in test set for minimum-trained classifier: 2367.289\n",
      "Score when trained on minimum training set: : 0.70292\n",
      "Information remaining in test set for classifier trained on almost all 0 labels: 3666.000\n",
      "Score when trained on almost all 0 labels : 0.52359\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx_0s = np.where(y_train == 0)[0] \n",
    "idx_0splus1 = np.unique(np.append(min_idx, idx_0s)) # a training set of almost all zeros will not tell us much about the test set\n",
    "clf.fit(X_train[idx_0splus1],y_train[idx_0splus1])\n",
    "almost_all_zero_test_info = btv.core.prediction_info(y_test, clf.predict_proba(X_test)).sum()\n",
    "\n",
    "print(f\"Information in the test set from frqunecy stats: {frequnecy_test_info:.3f}\")\n",
    "print(f\"Information remaining in test set for fully-trained classifier: {trained_test_info:.3f}\")\n",
    "print(f\"Score when trained on full training set: : {full_train_score:0.5f}\")\n",
    "print(f\"Information remaining in test set for minimum-trained classifier: {min_trained_test_info:.3f}\")\n",
    "print(f\"Score when trained on minimum training set: : {min_trained_score:0.5f}\")\n",
    "print(f\"Information remaining in test set for classifier trained on almost all 0 labels: {almost_all_zero_test_info:.3f}\")\n",
    "print(f\"Score when trained on almost all 0 labels : {clf.score(X_test,y_test):0.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b85c26-f802-4b9d-9767-5a5b7b55b09c",
   "metadata": {},
   "source": [
    "NB: When using a random forest classifier on the electricity data set (OpenML id = 44156), the classifier trained on almost all zeros did *worse* than on trained on only two samples. It left more information in the test set ($\\approx100$ bits) and scored $\\approx1$% worse. This is not too surprizing since the training set with only one sample of each labels reflects the class balance of the test set.\n",
    "\n",
    "It is tempting to say that we can answer the question posed in the first paragraph: if a fine-tuning set has less information for a model than the test set, it is insufficient. However, information scales with the size of the set and a small training set may contain all the paterns necissary to teach the model to classify a large test set well. Entropy (average information) is insensitive to class balance\n",
    "\n",
    "# Training Data Selection\n",
    "So Shnnon information is behaving as expected, giving a quanitative measure of how ignorant a classifier is about certain set of labels. If we are in the position of having to chose a training set however, information alone is not enough. Information a set contains for a given classifier scales with its size, while performance (and information remaining in a test set) once trained does not. What is more, ideally, we would select training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da778ff-9b35-4054-9a9a-26085ebf7c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8424f1-60a6-4376-aeed-0d656f78401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosing between fine-tuning sets\n",
    "ds = data_tab.getdata(44156, verbose=False)\n",
    "df, X, y = data_tab.dataset2df(ds, class_cols=[\"class\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=1.0, max_depth=1, random_state=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_dev1, y_train, y_dev1 = train_test_split(X_train, y_train, test_size=0.2)\n",
    "X_train, X_dev2, y_train, y_dev2 = train_test_split(X_train, y_train, test_size=0.2)\n",
    "X_train, X_dev3, y_train, y_dev3 = train_test_split(X_train, y_train, test_size=0.2)\n",
    "X_train, X_dev4, y_train, y_dev4 = train_test_split(X_train, y_train, test_size=0.2)\n",
    "X_train, X_dev5, y_train, y_dev5 = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "X_ft_list = [X_dev1, X_dev2, X_dev3, X_dev4, X_dev5]\n",
    "y_ft_list = [y_dev1, y_dev2, y_dev3, y_dev4, y_dev5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
