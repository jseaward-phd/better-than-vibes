{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06b4f84c-1266-4ad0-af31-778097103f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,  # use X = np.zeros(n_samples) in .split\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "\n",
    "from img_data import Img_Obj_Dataset\n",
    "\n",
    "# if you have indeces and want knns from large set, can make an idx array and NearestVectorCaller._call_vec_set; can just train/test split np.arange(len(ds)) to get back indeces for large sets\n",
    "\n",
    "\n",
    "from btv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34820869-08c5-4797-b66c-039cc3b7d91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detemining all classes...: 100%|██████████████████████████████| 1766/1766 [00:00<00:00, 2149.52it/s]\n"
     ]
    }
   ],
   "source": [
    "## Data setup\n",
    "\n",
    "ds = Img_Obj_Dataset(\"data/hardhat/test\", max_dim=256)\n",
    "# can pass metric == \"cosine\", get from NearestVectorCaller.metric on large sets\n",
    "knn = KNeighborsClassifier(weights=\"distance\", n_neighbors=5) #, metric = \"cosine\")\n",
    "# X, y = ds.whole_img_vec_set[:] # only need y for class balancing... ds.whole_img_vec_set.y\n",
    "\n",
    "idx_train, idx_test = train_test_split(\n",
    "    np.arange(len(ds.whole_img_vec_set)), test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6abb3ed6-794e-4bcc-8b4b-c3cb604ff6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(weights='distance')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(ds.whole_img_vec_set.X[idx_train], ds.whole_img_vec_set.y[idx_train])\n",
    "# knn.predict(X_test)\n",
    "# ds.whole_img_vec_set.X[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86b70ff0-5ef1-46f5-91e8-fe456f36f775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.748587570621469"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    ds.whole_img_vec_set.y[idx_test], knn.predict(ds.whole_img_vec_set.X[idx_test])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c387d5e-a9f9-45c1-976b-b4e8e1c0208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include p if y==1 or, reeally, want p(right answer) so take elemnt of predicted prob indicated by binary y.\n",
    "def prediction_entropy(y_true, y_predicted): # multilable\n",
    "    # replace log(0) with n instead of -Inf\n",
    "    if isinstance(y_predicted, list):\n",
    "        y_predicted = np.stack(y_predicted, axis=1)\n",
    "    A = np.zeros_like(y_true)\n",
    "    with np.errstate(divide=\"ignore\"):\n",
    "        for i, (pred, true) in enumerate(zip(y_predicted, y_true)):\n",
    "            for j, (p, t) in enumerate(zip(pred, true)):\n",
    "                I = -np.log(p[t])\n",
    "                if np.isinf(I):\n",
    "                    I = y_true.size\n",
    "                A[i, j] = I\n",
    "    return np.mean(A, axis=0)\n",
    "\n",
    "\n",
    "# probably actually want to do this at the prediction level since that is the big/slow bit.\n",
    "def prediction_entropy_lg(y_true, y_predicted): # sinlge label\n",
    "    # replace log(0) with n instead of -Inf\n",
    "    if isinstance(y_predicted, list):\n",
    "        y_predicted = np.stack(y_predicted, axis=1)\n",
    "    with np.errstate(divide=\"ignore\"):\n",
    "        for pred, true in zip(y_predicted, y_true):\n",
    "            for p, t in zip(pred, true):\n",
    "                I = -np.log(p[t])\n",
    "                if np.isinf(I):\n",
    "                    I = y_true.size\n",
    "                yield I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "468bdc54-1880-48a3-a147-f64342d080a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = knn.predict(ds.whole_img_vec_set.X[idx_test])\n",
    "P = knn.predict_proba(\n",
    "    ds.whole_img_vec_set.X[idx_test]\n",
    ")  # predicts the probability of each class. For whole image hardhats it is a list of 3 (p(no), P(yes)) arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ed5e5ed-aacd-4a1f-b2c0-b1198091d312",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprediction_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_predicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/better-than-vibes/btv.py:36\u001b[0m, in \u001b[0;36mprediction_entropy\u001b[0;34m(y_true, y_predicted)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_predicted, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     35\u001b[0m     y_predicted \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(y_predicted, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m class_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43my_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     37\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,class_num])\n\u001b[1;32m     38\u001b[0m y_predicted \u001b[38;5;241m=\u001b[39m y_predicted\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,class_num,\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "prediction_entropy(y_predicted, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b38014cc-98ab-46c1-98a7-8ae41a3c4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_idx_gen = StratifiedKFold(n_splits=5).split(\n",
    "    np.zeros(len(ds.whole_img_vec_set)), np.sum(ds.whole_img_vec_set.y, axis=1)\n",
    ")\n",
    "# can just add all the labels to make it multiclass for splitting\n",
    "entropies = []\n",
    "running_train = []\n",
    "for k, (train_idx, test_idx) in enumerate(kfold_idx_gen):\n",
    "    running_train.append(test_idx)\n",
    "    # knn.fit(ds.whole_img_vec_set.X[train_idx], ds.whole_img_vec_set.y[train_idx])\n",
    "    # y_predicted = knn.predict_proba(ds.whole_img_vec_set.X[test_idx])\n",
    "    # y_true = ds.whole_img_vec_set.y[test_idx]\n",
    "    # H = prediction_entropy(y_true, y_predicted)\n",
    "    # entropies.append(H)\n",
    "    # print(f\"Fold : {k+1}, \" f\"Fold entropy : {H}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02a465-f1c2-4835-a1ac-14c98a5dd875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f804cbeb-a4aa-4d4e-b430-3d8e53ad84cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([75.04532578, 57.61076487, 16.80113314]),\n",
       " array([38.20580196, 28.99206553,  8.40056667]),\n",
       " array([0.50910302, 0.50324042, 0.50000001]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(entropies, axis=0), np.std(entropies, axis=0), np.std(\n",
    "    entropies, axis=0\n",
    ") / np.mean(entropies, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "52f31aea-8cd9-4ea8-8d6a-b99228185d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(ds.whole_img_vec_set.X[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e3ab50b-7008-447f-b045-363b6e6e5ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 339, 1604,   45])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ds.whole_img_vec_set.y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd37861f-0139-4607-8803-06498c10d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1, Test set entropy : 45.036827195467424 Train samples : 354 Accuracy : 0.7705382436260623\n",
      "Fold : 2, Test set entropy : 45.040604343720496 Train samples : 707 Accuracy : 0.7648725212464589\n",
      "Fold : 3, Test set entropy : 47.038715769593956 Train samples : 1060 Accuracy : 0.7620396600566572\n",
      "Fold : 4, Test set entropy : 52.03305004721435 Train samples : 1413 Accuracy : 0.7592067988668555\n"
     ]
    }
   ],
   "source": [
    "## with straigh vectorization of whole images, the knn accuracy goes down as more data is added. Therefore that vecotrization is shit. Maybe we try tabular data?\n",
    "\n",
    "kfold_idx_gen = StratifiedKFold(n_splits=5).split(\n",
    "    np.zeros(len(ds.whole_img_vec_set)), np.sum(ds.whole_img_vec_set.y, axis=1)\n",
    ")\n",
    "train_idx = np.array([], int)\n",
    "running_train = []\n",
    "for k, (_, test_idx) in enumerate(kfold_idx_gen):\n",
    "    running_train.append(test_idx)\n",
    "running_test = running_train.pop()\n",
    "for k, old_test_idx in enumerate(running_train):\n",
    "    train_idx = np.append(train_idx,old_test_idx)\n",
    "    knn.fit(ds.whole_img_vec_set.X[train_idx], ds.whole_img_vec_set.y[train_idx])\n",
    "    y_predicted = knn.predict_proba(ds.whole_img_vec_set.X[running_test])\n",
    "    y_true = ds.whole_img_vec_set.y[running_test]\n",
    "    H = prediction_entropy(y_true, y_predicted)\n",
    "    entropies.append(H)\n",
    "    print(f\"Fold : {k+1}, \" f\"Test set entropy : {np.mean(H)}\", f\"Train samples : {len(train_idx)}\", f\"Accuracy : {accuracy_score(y_true,knn.predict(ds.whole_img_vec_set.X[test_idx]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcce42d3-8d73-4b1d-9fa0-b81cfbd43923",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hs, ss \u001b[38;5;241m=\u001b[39m \u001b[43madd_stratified_folds_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhole_img_vec_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhole_img_vec_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mknn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/better-than-vibes/btv.py:66\u001b[0m, in \u001b[0;36madd_stratified_folds_test\u001b[0;34m(X, y, clf, n_splits)\u001b[0m\n\u001b[1;32m     64\u001b[0m train_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([], \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     65\u001b[0m running_train, entropies, train_idx, scores \u001b[38;5;241m=\u001b[39m [], [], [], []\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, (_, test_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kfold_idx_gen):\n\u001b[1;32m     67\u001b[0m     running_train\u001b[38;5;241m.\u001b[39mappend(test_idx)\n\u001b[1;32m     68\u001b[0m running_test \u001b[38;5;241m=\u001b[39m running_train\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[0;32m~/.virtualenvs/study/lib/python3.10/site-packages/sklearn/model_selection/_split.py:352\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    346\u001b[0m         (\n\u001b[1;32m    347\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    350\u001b[0m     )\n\u001b[0;32m--> 352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/.virtualenvs/study/lib/python3.10/site-packages/sklearn/model_selection/_split.py:85\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     83\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m     84\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[1;32m     86\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[1;32m     87\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[0;32m~/.virtualenvs/study/lib/python3.10/site-packages/sklearn/model_selection/_split.py:733\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 733\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[1;32m    735\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[0;32m~/.virtualenvs/study/lib/python3.10/site-packages/sklearn/model_selection/_split.py:676\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    674\u001b[0m allowed_target_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_of_target_y \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_target_types:\n\u001b[0;32m--> 676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    677\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported target types are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    678\u001b[0m             allowed_target_types, type_of_target_y\n\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    682\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y)\n\u001b[1;32m    684\u001b[0m _, y_idx, y_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
     ]
    }
   ],
   "source": [
    "hs, ss = add_stratified_folds_test(ds.whole_img_vec_set.X,ds.whole_img_vec_set.y,knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "334d5b81-c0c8-4baa-98a0-2b92b35d3474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351,\n",
       "        352, 353, 354]),\n",
       " array([347, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366,\n",
       "        367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "        380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
       "        393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
       "        419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
       "        432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444,\n",
       "        445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457,\n",
       "        458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
       "        471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
       "        484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496,\n",
       "        497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
       "        510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522,\n",
       "        523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535,\n",
       "        536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548,\n",
       "        549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561,\n",
       "        562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574,\n",
       "        575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n",
       "        588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600,\n",
       "        601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613,\n",
       "        614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626,\n",
       "        627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639,\n",
       "        640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652,\n",
       "        653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665,\n",
       "        666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 678, 679, 680,\n",
       "        681, 682, 683, 684, 685, 686, 687, 689, 690, 691, 693, 695, 696,\n",
       "        697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709,\n",
       "        710, 714]),\n",
       " array([ 676,  677,  688,  692,  694,  711,  712,  713,  715,  716,  717,\n",
       "         718,  719,  720,  721,  722,  723,  724,  725,  726,  727,  728,\n",
       "         729,  730,  731,  732,  733,  734,  735,  736,  737,  738,  739,\n",
       "         740,  741,  742,  743,  744,  745,  746,  747,  748,  749,  750,\n",
       "         751,  752,  753,  754,  755,  756,  757,  758,  759,  760,  761,\n",
       "         762,  763,  764,  765,  766,  767,  768,  769,  770,  771,  772,\n",
       "         773,  774,  775,  776,  777,  778,  779,  780,  781,  782,  783,\n",
       "         784,  785,  786,  787,  788,  789,  790,  791,  792,  793,  794,\n",
       "         795,  796,  797,  798,  799,  800,  801,  802,  803,  804,  805,\n",
       "         806,  807,  808,  809,  810,  811,  812,  813,  814,  815,  816,\n",
       "         817,  818,  819,  820,  821,  822,  823,  824,  825,  826,  827,\n",
       "         828,  829,  830,  831,  832,  833,  834,  835,  836,  837,  838,\n",
       "         839,  840,  841,  842,  843,  844,  845,  846,  847,  848,  849,\n",
       "         850,  851,  852,  853,  854,  855,  856,  857,  858,  859,  860,\n",
       "         861,  862,  863,  864,  865,  866,  867,  868,  869,  870,  871,\n",
       "         872,  873,  874,  875,  876,  877,  878,  879,  880,  881,  882,\n",
       "         883,  884,  885,  886,  887,  888,  889,  890,  891,  892,  893,\n",
       "         894,  895,  896,  897,  898,  899,  900,  901,  902,  903,  904,\n",
       "         905,  906,  907,  908,  909,  910,  911,  912,  913,  914,  915,\n",
       "         916,  917,  918,  919,  920,  921,  922,  923,  924,  925,  926,\n",
       "         927,  928,  929,  930,  931,  932,  933,  934,  935,  936,  937,\n",
       "         938,  939,  940,  941,  942,  943,  944,  945,  946,  947,  948,\n",
       "         949,  950,  951,  952,  953,  954,  955,  956,  957,  958,  959,\n",
       "         960,  961,  962,  964,  965,  966,  967,  968,  969,  970,  971,\n",
       "         973,  974,  976,  977,  978,  979,  980,  981,  982,  983,  984,\n",
       "         985,  986,  987,  988,  990,  992,  993,  994,  996,  997,  998,\n",
       "         999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010,\n",
       "        1011, 1012, 1013, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023,\n",
       "        1024, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1033, 1034, 1035,\n",
       "        1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1047, 1048,\n",
       "        1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059,\n",
       "        1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070,\n",
       "        1071]),\n",
       " array([ 963,  972,  975,  989,  991,  995, 1002, 1014, 1015, 1028, 1038,\n",
       "        1046, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081,\n",
       "        1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092,\n",
       "        1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103,\n",
       "        1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114,\n",
       "        1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125,\n",
       "        1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136,\n",
       "        1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147,\n",
       "        1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158,\n",
       "        1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169,\n",
       "        1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180,\n",
       "        1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191,\n",
       "        1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202,\n",
       "        1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213,\n",
       "        1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224,\n",
       "        1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,\n",
       "        1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246,\n",
       "        1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257,\n",
       "        1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268,\n",
       "        1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279,\n",
       "        1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290,\n",
       "        1291, 1292, 1293, 1294, 1295, 1296, 1297, 1299, 1300, 1302, 1303,\n",
       "        1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314,\n",
       "        1315, 1316, 1317, 1318, 1319, 1321, 1322, 1323, 1324, 1326, 1327,\n",
       "        1328, 1329, 1330, 1331, 1333, 1334, 1335, 1336, 1337, 1338, 1339,\n",
       "        1340, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352,\n",
       "        1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363,\n",
       "        1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1375,\n",
       "        1376, 1377, 1379, 1380, 1382, 1384, 1385, 1386, 1387, 1388, 1389,\n",
       "        1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400,\n",
       "        1401, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1412, 1413,\n",
       "        1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424,\n",
       "        1425]),\n",
       " array([1298, 1301, 1320, 1325, 1332, 1341, 1342, 1374, 1378, 1381, 1383,\n",
       "        1402, 1411, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434,\n",
       "        1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445,\n",
       "        1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456,\n",
       "        1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467,\n",
       "        1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478,\n",
       "        1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489,\n",
       "        1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500,\n",
       "        1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511,\n",
       "        1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522,\n",
       "        1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533,\n",
       "        1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544,\n",
       "        1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555,\n",
       "        1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566,\n",
       "        1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577,\n",
       "        1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588,\n",
       "        1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599,\n",
       "        1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610,\n",
       "        1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621,\n",
       "        1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632,\n",
       "        1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643,\n",
       "        1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654,\n",
       "        1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665,\n",
       "        1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676,\n",
       "        1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687,\n",
       "        1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698,\n",
       "        1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709,\n",
       "        1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720,\n",
       "        1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731,\n",
       "        1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742,\n",
       "        1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753,\n",
       "        1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764,\n",
       "        1765])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caedb7b-8895-424c-bcf3-e0a1a8801a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
